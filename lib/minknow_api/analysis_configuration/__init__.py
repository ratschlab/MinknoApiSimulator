# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: minknow_api/analysis_configuration.proto
# plugin: python-betterproto
# This file has been @generated

from dataclasses import dataclass
from datetime import timedelta
from typing import (
    TYPE_CHECKING,
    Dict,
    List,
    Optional,
)

import betterproto
import betterproto.lib.google.protobuf as betterproto_lib_google_protobuf
import grpclib
from betterproto.grpc.grpclib_server import ServiceBase


if TYPE_CHECKING:
    import grpclib.server
    from betterproto.grpc.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline


class EventDetectionDetectionType(betterproto.Enum):
    MULTITTEST = 0
    DMEAN = 1


class ReadDetectionParamsReadDetectionMode(betterproto.Enum):
    none = 0
    transition = 1
    lookback = 2
    minmax = 3


class ReadClassificationParamsScheme(betterproto.Enum):
    none = 0
    parsed = 1


class WriterConfigurationCompressionType(betterproto.Enum):
    """
    Control the type of compression applied to the read data.

     By default the vbz compressor is used (except in the single read case).
    """

    DefaultCompression = 0
    ZlibCompression = 1
    VbzCompression = 2


@dataclass(eq=False, repr=False)
class EventDetection(betterproto.Message):
    type: "EventDetectionDetectionType" = betterproto.enum_field(19)
    window_size: int = betterproto.uint32_field(3)
    """The window size that the tstats are calculated from"""

    threshold: float = betterproto.double_field(5)
    """
    The peak detection must be above this threshold at a minimum for it to be detected
     as an event.
    """

    peak_height: float = betterproto.double_field(9)
    """
    When analysing the tstat peaks, if the jump between one value and another is higher than
     than 'peak_height', then it will "arm" the peak detector and move onto the next phase.
    
     And what goes up must come down.
     Once it has detected a peak going up, it will also have to go down by 'peak_height'
     in order for the peak to be classified as a found event
    
     Note: only used for MULTITTEST detector.
    """

    events_to_base_ratio: Optional[float] = betterproto.message_field(
        16, wraps=betterproto.TYPE_DOUBLE
    )
    """
    Conversion factor used to convert from events to bases.
    
     This is used to estimate bases for various rpc feeds from minknow.
    """

    break_on_mux_changes: bool = betterproto.bool_field(17)
    """
    Whether to break events on mux changes.
    
     This will eliminate "mux_uncertain" events and reads. Note that this will cause starting or
     stopping unblocking to break events as well (even though the mux does not normally change in
     this case).
    
     Note: no longer used.
    """

    max_mux_change_back_shift: int = betterproto.uint32_field(18)
    """
    Control the number of samples MinKNOW will shift mux changes back by in order to align mux changes
     with event boundaries.
    
     When break on mux changes is enabled its possible that mux changes recorded from the device and
     signal deltas caused by the config changes will not align exactly (the signal delta happen prior to the
     mux change due to the recorded sample indicating the command is fully applied). Setting this value to > 0
     will allow minknow to record the mux change as active up to this number of samples _before_ the device
     recorded the change as active. Mux changes are never shifted forwards.
    
     A value of 0 will disable shifting of mux changes.
    
     Note: no longer used.
    """


@dataclass(eq=False, repr=False)
class ReadDetectionParams(betterproto.Message):
    mode: "ReadDetectionParamsReadDetectionMode" = betterproto.enum_field(1)
    minimum_delta_mean: float = betterproto.double_field(2)
    look_back: int = betterproto.uint32_field(3)
    break_reads_after_events: Optional[int] = betterproto.message_field(
        4, wraps=betterproto.TYPE_UINT32
    )
    break_reads_after_seconds: Optional[float] = betterproto.message_field(
        5, wraps=betterproto.TYPE_DOUBLE
    )
    break_reads_on_mux_changes: bool = betterproto.bool_field(6)
    open_pore_min: Optional[float] = betterproto.message_field(
        7, wraps=betterproto.TYPE_DOUBLE
    )
    """
    The minimum level which is considered open pore (this value is relative to open_pore_default
     or the tracked open_pore section, if tracking is being used.)
    
     This value must be <= 0.0 if tracking is being used.
    """

    open_pore_max: Optional[float] = betterproto.message_field(
        8, wraps=betterproto.TYPE_DOUBLE
    )
    """
    The maximum level which is considered open pore (this value is relative to open_pore_default
     or the tracked open_pore section, if tracking is being used.)
    
     This value must be >= 0.0 if tracking is being used.
    """

    open_pore_default: Optional[float] = betterproto.message_field(
        9, wraps=betterproto.TYPE_DOUBLE
    )
    """
    The default value to use for open pore, either when tracking isn't being used, or when
     open pore tracking has no value currently.
    """

    open_pore_seconds_required: Optional[float] = betterproto.message_field(
        10, wraps=betterproto.TYPE_DOUBLE
    )
    """
    Minimum number of seconds events must lie within the range of open pore in order to allow
     a read to break.
    """


@dataclass(eq=False, repr=False)
class ReadFilters(betterproto.Message):
    """
    Parameters for filtering out reads from being written.

     The tests are combined using a logical AND: if any given test fails, the read will not be
     written. Only reads that pass all (non-zero) tests will be written out.

     Currently, it is only possible to filter on read length. This can be given in samples or MinKNOW
     events.
    """

    read_length_min: int = betterproto.uint32_field(1)
    """
    Only write reads that contain at least this many samples.
    
     The default zero value will not exclude any reads.
    """

    read_length_max: int = betterproto.uint32_field(2)
    """
    Only write reads that contain at most this many samples.
    
     If set to zero (the default), this test is not applied (as though it had been set to a value
     longer than any possible read).
    """

    event_count_min: int = betterproto.uint32_field(3)
    """
    Only write reads that contain at least this many MinKNOW events.
    
     The default zero value will not exclude any reads.
    """

    event_count_max: int = betterproto.uint32_field(4)
    """
    Only write reads that contain at most this many MinKNOW events.
    
     If set to zero (the default), this test is not applied (as though it had been set to a value
     longer than any possible read).
    """

    skip_rejected_reads: bool = betterproto.bool_field(5)
    """
    Control whether reads unblocked using from `DataService::get_live_reads()` should be filtered.
    
     When set to true, reads which are unblocked by `get_live_reads` are filtered and therefore not basecalled.
     When set to false, reads that are unblocked by `get_live_reads` will not be filtered and therefore will be basecalled.
    """


@dataclass(eq=False, repr=False)
class ReadClassificationParams(betterproto.Message):
    scheme_module: "ReadClassificationParamsScheme" = betterproto.enum_field(1)
    max_sample_size: Optional[int] = betterproto.message_field(
        2, wraps=betterproto.TYPE_UINT64
    )
    """
    This tells minknow the maximum number of means to store in memory before using a different strategy
     to calculate medians. If the number of means goes over this size then the strategy used may
     be less accurate, but will not use as much memory in minknow
    """

    selected_classifications: List[str] = betterproto.string_field(3)
    """
    A list of classifications that are deemed interesting, and will be marked to be written out to file
    """

    open_pore_classifications: List[str] = betterproto.string_field(6)
    """
    A set of classifications whose level should be tracked as the level of open pore (fed back into
     read detection analysis).
    
     Read chunks selected by this filter will be aggregated for use in read detection.
    """

    open_pore_ewma_weight: Optional[float] = betterproto.message_field(
        7, wraps=betterproto.TYPE_DOUBLE
    )
    """
    A weighting figure for the exponentially weighted moving average given to the newest data.
     eg. 0.7 would weight new data with 0.3 and all previous data with 0.7.
    
     By default 0.5 is used.
    """

    open_pore_ignore_after_reset_seconds: Optional[float] = betterproto.message_field(
        8, wraps=betterproto.TYPE_DOUBLE
    )
    """
    A number of seconds to ignore new chunks for after a reset occurs on a channel
     this allows analysis to ignore spikes or bad data on the channel for a small section of time.
    
     By default 0.0 is used - and chunks are accepted immediately.
    """

    classification_strategy: str = betterproto.string_field(4)
    """
    Determine how to classify a whole read based on the strategy
    
     'ultimate':      Chooses the last (ultimate) read chunk's classification
     'penultimate':   Chooses the second-to-last read chunk's classification
     'modal':         Chooses the most common classification out of all read chunks
     'threshold':     Chooses a classification based on the combination of threshold parameters.
                      If selected, values for the "selected_classifications_fraction_required"
                      and "selected_chunks_required" fields will be used to determine the
                      read classification (see below).
    """

    parameters: "ReadClassificationParamsParameters" = betterproto.message_field(5)
    selected_classifications_fraction_required: Optional[float] = (
        betterproto.message_field(9, wraps=betterproto.TYPE_DOUBLE)
    )
    """
    For the "threshold" classification strategy, specify the minimum fraction (in duration) of a completed read
     that needs to be in any of the "selected_classifications".
     For example, using 0 means that all reads will written out unless further constrained by the
     "selected_classifications_chunk_required" field.
    
     Note that this option only applies to the 'threshold' classification strategy and will be ignored
     for other classification strategies.
    """

    selected_classifications_chunks_required: Optional[int] = betterproto.message_field(
        10, wraps=betterproto.TYPE_UINT32
    )
    """
    For the "threshold" classification strategy, specify the minimum number of chunks of a completed read
     that needs to be in any of the "selected_classifications".
     For example, using 1 means that the entire read will be written if ANY chunk has a classification in
     "selected_classifications" unless further constrained by the "selected_classifications_fraction_required" field.
    
     Note that this option only applies to the 'threshold' classification strategy and will be ignored
     for other classification strategies.
    """

    merge_selected_classifications: Optional[bool] = betterproto.message_field(
        11, wraps=betterproto.TYPE_BOOL
    )
    """
    this parameter controls whether (or not)  we merge data for all selected classifications into a single
     data point before deciding whether to output a read.
     For instance, if 2 classifications are selected and classification A is 20% of the read, and classification B
     is 20% of the read then:
     When merge_selected_classifications is set to true, the overall selected classification proportion would amount
     to 40% of the read and that value would used when deciding whether or not to output the read.
     When merge_selected_classifications is set to false, each selected classification would be considered
     separately at the decision stage. Defaults to false.
     Note that when multiple classifications are selected by the user and the threshold criteria are met, then the
     most recent classification (of all selected classifications) will be used as the read overall classification.
    """

    max_read_length_before_selected_decision_seconds: Optional[int] = (
        betterproto.message_field(12, wraps=betterproto.TYPE_UINT64)
    )
    """
    Limit on how long a read may be in seconds before minknow forces the selected decision and either
     selects or vetoes the complete read.
    
     If unspecified a default value is used.
    """

    metrics_ewma: "ReadClassificationParamsMetricsEwma" = betterproto.message_field(13)
    """
    Configuration for Exponentially weighted moving averages over read metrics.
     These values configure how sensitive the complete read metrics are to per chunk changes in value;
     higher values in the config here cause an increase in sensitivity in the metrics to per chunk changes.
    
     The values provided here are biased based on the length of each chunk, so short chunks will have less
     effect on the computed metric than longer chunks.
    
     A value of 1.0 will take as much of the local chunk value as possible, while values closer to zero will
     make the computed metric slower moving.
    
     The default weight if unspecified is 0.1.
    """


@dataclass(eq=False, repr=False)
class ReadClassificationParamsParameters(betterproto.Message):
    rules_in_execution_order: List[str] = betterproto.string_field(2)
    """
    An execution rule has the following format:
    
     "pore = (median,gt,185)&(median,lt,260)&(median_sd,lt,40)"
    
     "median" and "median_sd" are apart of a small subset of variable values describing a read or read chunk,
     that are exposed to execution rules. The full list of variable values and their descriptions are documented
     here: https://minknow.git.oxfordnanolabs.local/minknow-core/analysis/reads.html
    
     "gt" and "lt" describe how data can be compared:
     gt: greater than
     lt: less than
     eq: equal
     ne: not equal
    
     Constant values like "185" or "260" can also be specified. These can be real numbers also.
    
     Note that variables dont always have to be on the left and const values on the right. The
     following sub rules are also valid:
    
     (200,lt,median_sd)
     (median_before,gt,median)
     (5,lt,10)
    """


@dataclass(eq=False, repr=False)
class ReadClassificationParamsMetricsEwma(betterproto.Message):
    median: Optional[float] = betterproto.message_field(1, wraps=betterproto.TYPE_FLOAT)
    median_sd: Optional[float] = betterproto.message_field(
        2, wraps=betterproto.TYPE_FLOAT
    )
    range: Optional[float] = betterproto.message_field(3, wraps=betterproto.TYPE_FLOAT)
    median_dwell: Optional[float] = betterproto.message_field(
        4, wraps=betterproto.TYPE_FLOAT
    )
    dwell_sd: Optional[float] = betterproto.message_field(
        5, wraps=betterproto.TYPE_FLOAT
    )
    read_chunks_required_for_ewma: Optional[int] = betterproto.message_field(
        6, wraps=betterproto.TYPE_INT32
    )
    """
    How many read chunks are required before an ewma is calculated.
    
     If we don't use ewma, a straight mean of all samples so far is used instead.
    
     Default value is 0: Always use ewma.
    """


@dataclass(eq=False, repr=False)
class ChannelStates(betterproto.Message):
    group: "ChannelStatesGroup" = betterproto.message_field(2)
    description: str = betterproto.string_field(5)
    logic: "ChannelStatesLogic" = betterproto.message_field(3)
    style: "ChannelStatesStyle" = betterproto.message_field(4)


@dataclass(eq=False, repr=False)
class ChannelStatesLogic(betterproto.Message):
    criteria: str = betterproto.string_field(1)
    rank: int = betterproto.int32_field(3)
    """
    Specifies the order in which channel state criteria will be evaluated; the
     smaller the number, the earlier it will be evaluated. The first criteria to match
     will be selected
    """

    pattern: str = betterproto.string_field(4)
    """
    Note that this is a regex based pattern for describing a read classification
     sequence. For example you can specify:
          "unavailableunavailable"
     or:
          "(unavailable)(unavailable)"
    
     to recognise two consecutive read chunks classified as unavailable.
    
     You can also use "?" at the end of one of the classifications in the sequence
     to indicate that it may or may not be present at that point. For example:
          "(pore)(transition)?(event)"
    
     This will match both of the sequences:
          pore, transition, event
          pore, event
    
     The technical documentation has more information on the range of regex patterns you can
     apply. https://minknow.git.oxfordnanolabs.local/minknow-core/analysis/channel-states.html
    """

    classification: str = betterproto.string_field(5)
    ranges: "ChannelStatesLogicRanges" = betterproto.message_field(6)
    """Range is [lower_pa, upper_pa)"""

    behaviour: "ChannelStatesLogicBehaviour" = betterproto.message_field(7)


@dataclass(eq=False, repr=False)
class ChannelStatesLogicBehaviour(betterproto.Message):
    reset_on_mux_change: int = betterproto.int32_field(1)
    """
    TODO: MinKNOW 5: replace int32 with bool for these options
     these are ints but act like bools
    """

    reset_on_well_change: int = betterproto.int32_field(2)
    latch: int = betterproto.int32_field(3)
    """
    If the latch value is set to true, then when the criteria for this channel state
     is active, then the latch will keep it active until the channel state is reset.
    """

    reset_on_effective_mux_change: int = betterproto.int32_field(4)
    """
    An 'effective mux change' is any mux change apart from the one triggered
     with the purpose of disconnecting a channel (turning a channel off). For example, if
     a channel is in pore, and the user changes the channel configuration to 'disconnected',
     that mux change will not be an effective mux change. Any other mux change is considered
     an 'effective mux change'. So if a channel saturates,
     the mux change to disconnected is an effective mux change. Similarly, a
     change from disconnected to a pore is an effective mux change.
    
     Use this reset mode to make the channel state persist on non-effective mux changes.
     For example, if a channel state is in 'multiple' and the user triggers a channel
     configuration change to 'disconnected', the state will remain in multiple if it has
     this option on. The multiple state will be reset at all other mux changes (i.e. effective
     mux changes).
    """

    reset_on_effective_well_change: int = betterproto.int32_field(5)
    """
    An 'effective well change' is any well change apart from the one triggered
     with the purpose of disconnecting a channel (turning a channel off). For example, if
     a channel is in well_1, and the user changes the channel configuration to 'unblock_1',
     that change will not be an effective well change. A change to disconnected is also
     not considered an effective well change.
    
     Use this reset mode to make the channel state persist on non-effective well changes.
     For example, if a channel state is in 'multiple' and the user triggers a channel
     configuration change to 'disconnected', the state will remain in multiple if it has
     this option on. The multiple state will be reset then when the mux is set to a different
     setting.
    """


@dataclass(eq=False, repr=False)
class ChannelStatesLogicRanges(betterproto.Message):
    """
    Dont really like this way of doing it, but it has to match the old way...
    """

    range: "ChannelStatesLogicRangesRange" = betterproto.message_field(1)


@dataclass(eq=False, repr=False)
class ChannelStatesLogicRangesRange(betterproto.Message):
    lower_pa: int = betterproto.int32_field(1)
    upper_pa: int = betterproto.int32_field(2)


@dataclass(eq=False, repr=False)
class ChannelStatesStyle(betterproto.Message):
    order: Optional[int] = betterproto.message_field(1, wraps=betterproto.TYPE_UINT32)
    label: str = betterproto.string_field(2)
    colour: str = betterproto.string_field(3)


@dataclass(eq=False, repr=False)
class ChannelStatesGroup(betterproto.Message):
    name: str = betterproto.string_field(1)
    style: "ChannelStatesStyle" = betterproto.message_field(2)
    description: str = betterproto.string_field(3)


@dataclass(eq=False, repr=False)
class GetAnalysisConfigurationRequest(betterproto.Message):
    run_id: str = betterproto.string_field(1)
    """
    The unique identifier assigned to this acquisition run.
    
     Since 6.2
    """


@dataclass(eq=False, repr=False)
class ReadScalingParams(betterproto.Message):
    """Since 5.3"""

    quantile_locations: List[float] = betterproto.float_field(3)
    """
    Position of quantiles in scaling data to use when computing scale parameters.
    """

    quantile_weights_shift: List[float] = betterproto.float_field(1)
    """
    If present, must be the same length as quantile_locations.
     Represents the coefficients that shall be multiplied with measured quantiles to give a predicted_shift
    """

    quantile_weights_scale: List[float] = betterproto.float_field(2)
    """
    If present, must be the same length as quantile_locations.
     Represents the coefficients that shall be multiplied with measured quantiles to give a predicted_scale
    """

    tracking_alpha: float = betterproto.float_field(4)
    """
    Alpha value to use in ewma calculation for scale and shift tracking. 1 updates instantly. 0 does not update.
    """

    alpha_number_estimates_decay: float = betterproto.float_field(5)
    """
    Alpha decay value to use. Higher values cause a more rapid decay in greater trust of earlier numbers.
    """

    quantile_maxdiff: float = betterproto.float_field(10)
    """
    Maximum difference in event quantiles which will be added into trackers.
     This is used to filter away cases where pore signal is included in the read and thus cannot be trusted.
    """

    trust_limit_fraction: float = betterproto.float_field(6)
    """
    Maximum fraction change between one tracked value and the next which will be trusted. Higher values are not trusted.
    """

    diff_threshold: float = betterproto.float_field(7)
    """
    The minimum difference between an event and the next to include it in the subsampling
    """

    emission_threshold: float = betterproto.float_field(8)
    """
    After how many cumulative pA is a new event emitted in the subsampling
    """

    dacs_breakpoint: float = betterproto.float_field(9)
    """
    Cumulative pA sum required to compute scaling. Any events after this sum are not considered in scaling.
    """

    conductance_factor_scale: float = betterproto.float_field(11)
    """
    Scale factor applied to conductance to produce a basic scale estimate, also combined with q90_q10_to_normal.
    """

    conductance_factor_shift: float = betterproto.float_field(12)
    """
    Scale factor applied to conductance to produce a basic shift estimate.
    """

    q90_q10_to_normal: float = betterproto.float_field(13)


@dataclass(eq=False, repr=False)
class AnalysisConfiguration(betterproto.Message):
    event_detection: "EventDetection" = betterproto.message_field(1)
    read_detection: "ReadDetectionParams" = betterproto.message_field(2)
    read_classification: "ReadClassificationParams" = betterproto.message_field(4)
    channel_states: Dict[str, "ChannelStates"] = betterproto.map_field(
        7, betterproto.TYPE_STRING, betterproto.TYPE_MESSAGE
    )
    read_scaling: "ReadScalingParams" = betterproto.message_field(8)
    """
    Add read scale tracking to the pipeline.
     If this message is unspecified, read scaling is not enabled.
    """


@dataclass(eq=False, repr=False)
class SetAnalysisConfigurationResponse(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class ResetAnalysisConfigurationRequest(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class ResetAnalysisConfigurationResponse(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class SetAnalysisEnabledStateRequest(betterproto.Message):
    enable: bool = betterproto.bool_field(1)


@dataclass(eq=False, repr=False)
class SetAnalysisEnabledStateResponse(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class GetChannelStatesDescRequest(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class GetChannelStatesDescResponse(betterproto.Message):
    groups: List["GetChannelStatesDescResponseGroup"] = betterproto.message_field(1)
    """
    The groups of channel states.
    
     The groups are ordered according to the "order" attribute of the group style in the channel
     states configuration.
    """


@dataclass(eq=False, repr=False)
class GetChannelStatesDescResponseStyle(betterproto.Message):
    label: str = betterproto.string_field(1)
    """
    The human-readable name to display when rendering this channel state or group.
    """

    description: str = betterproto.string_field(2)
    """
    A sentence describing the meaning of the channel state or group.
    
     This can be used as a tooltip, for example.
    """

    colour: str = betterproto.string_field(3)
    """
    The colour to use when rendering this channel state or group.
    
     This is a six-digit hex string describing an RGB colour (eg: "ff00ff" for purple).
    """


@dataclass(eq=False, repr=False)
class GetChannelStatesDescResponseChannelState(betterproto.Message):
    id: int = betterproto.uint32_field(1)
    """
    The numeric identifier of the state.
    
     This is what is reported in any other APIs that return a channel state ID.
    """

    name: str = betterproto.string_field(2)
    """
    The internal name of the state.
    
     This is what is reported in any other APIs that return a channel state name.
    """

    style: "GetChannelStatesDescResponseStyle" = betterproto.message_field(3)
    """
    How to render the channel state in a graphical user interface.
    
     Note that the style may be missing from some channel states (such as the ones that are
     built in to MinKNOW).
    """

    global_order: int = betterproto.uint32_field(4)
    """
    An order ranking for the channel states when they are ungrouped.
    
     This can be used to order the channel states after merging the groups.
    """


@dataclass(eq=False, repr=False)
class GetChannelStatesDescResponseGroup(betterproto.Message):
    name: str = betterproto.string_field(1)
    """The name of the group."""

    style: "GetChannelStatesDescResponseStyle" = betterproto.message_field(2)
    """
    How to render the group in a graphical user interface.
    
     Note that the style may be missing from some groups (such as the ones that are built in
     to MinKNOW).
    """

    states: List["GetChannelStatesDescResponseChannelState"] = (
        betterproto.message_field(3)
    )
    """
    The channel states contained in the group.
    
     The groups are ordered according to the "order" attribute of the channel state style in
     the channel states configuration.
    """


@dataclass(eq=False, repr=False)
class GetSummaryRequest(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class GetSummaryResponse(betterproto.Message):
    analysis_enabled: bool = betterproto.bool_field(1)
    """
    Whether any analysis is enabled.
    
     If this is false, everything else will be false as well.
    """

    basecalling_enabled: bool = betterproto.bool_field(2)
    """Whether basecalling is enabled."""


@dataclass(eq=False, repr=False)
class BarcodingConfiguration(betterproto.Message):
    """Since 3.5"""

    barcoding_kits: List[str] = betterproto.string_field(1)
    """
    The barcoding kits in use
     One entry per kit
     If no barcoding kits are supplied, barcoding is disabled.
    """

    trim_barcodes: bool = betterproto.bool_field(2)
    """
    Whether the basecaller should trim barcodes
     If not specified, this value defaults to false (not trimming barcodes)
     If barcoding is not enabled (e.g., because no barcoding kits are specified),
     this parameter has no effect.
    """

    require_barcodes_both_ends: bool = betterproto.bool_field(3)
    """
    Barcode is only classified if a barcode above `min_score` is present at both ends of the basecalled read.
    """

    ignore_unspecified_barcodes: bool = betterproto.bool_field(9)
    """
    If set, barcodes that aren't in barcode user data list will be ignored
    
     Since 5.6
    """


@dataclass(eq=False, repr=False)
class AlignmentConfiguration(betterproto.Message):
    """Since 4.0"""

    reference_files: List[str] = betterproto.string_field(1)
    """
    Provide an index to align reads against once basecalled.
    
     Any acceptable reference format to the basecaller can be passed here:
       - fasta reference file
       - minimap index file
    """

    bed_file: str = betterproto.string_field(2)
    """
    Provide a bed file for use indicating areas of interest in alignment results.
    
     Note: alignment_index must be provided for this argument to be valid.
    """

    minimum_coverage: Optional[float] = betterproto.message_field(
        3, wraps=betterproto.TYPE_FLOAT
    )
    """
    Minimum coverage for the basecaller to accept an alignment.
    
     If not specified a default value is used.
    
     Note: this option cannot be used during live basecalling.
    """

    aggregate_statistics_for_multiple_bed_hits: bool = betterproto.bool_field(4)
    """
    Control how statistics for bed results are aggregated.
    
     If set to false only the bed hit with the highest overlap is
     used when computing heatmap/throughput graphs with bed hits.
    
     If set to true each bed hit is considered and bases for all hits are counted.
     This may give more honest representation of individual bed hit results
     but will skew read count statistics - as each hit will be counted for every
     bed hit.
    
     Note: this option has no effect in offline basecalling.
    """


@dataclass(eq=False, repr=False)
class LampConfiguration(betterproto.Message):
    """
    Since 4.1

     DEPRECATED 6.0: Lamp support has been removed and all of these options will be ignored.
    """

    lamp_kit: str = betterproto.string_field(1)
    """Set the lamp kit being used."""

    min_score_barcodes: Optional[float] = betterproto.message_field(
        2, wraps=betterproto.TYPE_FLOAT
    )
    """Optionally specify a min score to detect a valid lamp barcode."""

    min_score_masks: Optional[float] = betterproto.message_field(
        3, wraps=betterproto.TYPE_FLOAT
    )
    """Optionally set the minimimum valid score for a lamp mask."""

    min_score_targets: Optional[float] = betterproto.message_field(
        4, wraps=betterproto.TYPE_FLOAT
    )
    """Optionally specify a minimum score for lamp targets."""


@dataclass(eq=False, repr=False)
class BasecallerConfiguration(betterproto.Message):
    """Since 3.0"""

    enable: bool = betterproto.bool_field(2)
    """
    Choose if the basecaller is enabled or disabled.
    
     If set to false then no basecalling will take place, and the rest of the config is ignored.
    """

    config_filename: str = betterproto.string_field(1)
    """
    The basecaller cfg file with all the settings.
    
     Filename can be absolute, or a basename (eg dna_r9.4_450bps.cfg)
     which the basecaller should locate (see basecaller application config entry: "data_path")
    """

    align_filter: bool = betterproto.bool_field(10)
    """
    Enable or disable pass/fail filtering based on alignment.  When enabled, reads which
     do not align to any references will be marked as "failed", and written to the folder
     specified in MinKNOW configuration for failed reads.
    
     The setting applies to both regular read filtering and target filtering; if it is
     enabled, then a read will not be marked as a target read if it does not align to a reference.
    
     Default setting is false, i.e. disabled.
    
     Since 5.4
    """

    read_filtering: "BasecallerConfigurationReadFiltering" = betterproto.message_field(
        3
    )
    """
    Control how read filtering is applied to output of basecaller.
     These settings determine whether a read is marked as "passed"
     or "failed".  Reads are written to different folders based on
     the result of this filtering.  Those folders are specified in
     MinKNOW configuration.
    
     If no filtering parameters are provided then reads will not
     be filtered.
    """

    barcoding_configuration: "BarcodingConfiguration" = betterproto.message_field(4)
    """
    Control the barcoding configuration.
     If no barcoding configuration is supplied, barcoding is disabled.
    
     Since 3.5
    """

    target_filtering: "BasecallerConfigurationTargetFiltering" = (
        betterproto.message_field(5)
    )
    """
    Control how target filtering is applied to output of basecaller.
     Reads which pass these filtering criteria will be marked as
     "target" reads, and will be written to a separate folder; this
     folder is specified in MinKNOW configuration.  Reads which do
     not pass these criteria will have the regular read filtering
     applied to them, as specified by the `read-filtering` settings
     above.
    
     If no filtering parameters are provided then reads will not
     be target-filtered.
    
     Since 3.7
    """

    alignment_configuration: "AlignmentConfiguration" = betterproto.message_field(6)
    """
    Alignment configuration parameters.
     If no configuration is specified alignment is disabled.
    
     Since 4.0
    """

    lamp_configuration: "LampConfiguration" = betterproto.message_field(7)
    """
    Lamp configuration parameters.
     If no configuration is specified lamp is disabled.
    
     Since 4.1
    
     DEPRECATED 6.0: Lamp support has been removed and this option will be ignored.
    """

    enable_read_splitting: bool = betterproto.bool_field(8)
    """
    Enable read splitting in the basecaller.
    
     Since 4.5
    
     Note: Since 5.9 this option has no effect, the basecaller is responsible for deciding when read splitting should be enabled.
    """

    min_score_read_splitting: Optional[float] = betterproto.message_field(
        9, wraps=betterproto.TYPE_FLOAT
    )
    """
    Override score to use for the basecaller read splitting. If not specified a default value
     is used from the basecaller.
    
     Since 4.5
    
     Note: Since 5.9 this option has no effect, the basecaller is responsible for deciding read splitting score.
    """


@dataclass(eq=False, repr=False)
class BasecallerConfigurationReadFiltering(betterproto.Message):
    min_qscore: Optional[float] = betterproto.message_field(
        1, wraps=betterproto.TYPE_DOUBLE
    )
    min_bases: Optional[int] = betterproto.message_field(
        4, wraps=betterproto.TYPE_UINT64
    )
    max_bases: Optional[int] = betterproto.message_field(
        5, wraps=betterproto.TYPE_UINT64
    )
    min_duplex_qscore: Optional[float] = betterproto.message_field(
        7, wraps=betterproto.TYPE_DOUBLE
    )
    """Since 5.8"""


@dataclass(eq=False, repr=False)
class BasecallerConfigurationTargetFiltering(betterproto.Message):
    """Since 3.7"""

    min_qscore: Optional[float] = betterproto.message_field(
        1, wraps=betterproto.TYPE_DOUBLE
    )
    min_bases: Optional[int] = betterproto.message_field(
        2, wraps=betterproto.TYPE_UINT64
    )
    max_bases: Optional[int] = betterproto.message_field(
        3, wraps=betterproto.TYPE_UINT64
    )


@dataclass(eq=False, repr=False)
class SetBasecallerConfigurationRequest(betterproto.Message):
    configs: "BasecallerConfiguration" = betterproto.message_field(1)


@dataclass(eq=False, repr=False)
class SetBasecallerConfigurationResponse(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class GetBasecallerConfigurationRequest(betterproto.Message):
    run_id: str = betterproto.string_field(1)
    """
    The unique identifier assigned to this acquisition run.
    
     Since 6.0
    """


@dataclass(eq=False, repr=False)
class GetPoreTypeConfigurationRequest(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class PoreTypeConfiguration(betterproto.Message):
    """
    The pore type configuration

     The ways of specifying a configuration are as follows:
     - global_pore_type: all wells have a pore type of global_pore_type.
     - channel_well_pore_types: channels are allowed different values per channel/well
       (allows a subset of channels to be set).
    """

    global_pore_type: str = betterproto.string_field(1, group="pore_type_config")
    """Set all channel/wells to one pore type."""

    channel_well_pore_types: (
        "PoreTypeConfigurationChannelWellPoreTypeConfigurations"
    ) = betterproto.message_field(2, group="pore_type_config")
    """
    Set channel/wells to different pore types.
    
     Pore types can be created without being used by adding an empty
     entry.
    """


@dataclass(eq=False, repr=False)
class PoreTypeConfigurationChannelWell(betterproto.Message):
    channel: int = betterproto.uint32_field(1)
    """
    Channel number to control pore type for.
    
     Must be less than channel count for the current platform
    """

    well: int = betterproto.uint32_field(2)
    """
    Well to control pore type for.
    
     Wells outside the available wells on the flowcell are ignored.
    """


@dataclass(eq=False, repr=False)
class PoreTypeConfigurationChannelWellPoreTypeConfigurations(betterproto.Message):
    pore_types: Dict[
        str, "PoreTypeConfigurationChannelWellPoreTypeConfigurationsChannelWellList"
    ] = betterproto.map_field(1, betterproto.TYPE_STRING, betterproto.TYPE_MESSAGE)
    """
    Map with pore type as key, mapped to the list of wells to set for.
    
     It is undefined what will happen if one call sets the pore type of
     a channel and well to two pore types.
    """


@dataclass(eq=False, repr=False)
class PoreTypeConfigurationChannelWellPoreTypeConfigurationsChannelWellList(
    betterproto.Message
):
    channel_well: List["PoreTypeConfigurationChannelWell"] = betterproto.message_field(
        1
    )


@dataclass(eq=False, repr=False)
class SetPoreTypeConfigurationResponse(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class WriterConfiguration(betterproto.Message):
    """
    Configuration for the output writers for MinKNOWs
     analysis pipeline.

     Each writer has its own section in this message, where individual data elements
     can be enabled or disabled.

     File pattern attributes
     -----------------------
     Writers have a 'file_pattern' field which controls where individual files will be
     written to. The pattern is expanded for each individual read, and then the read
     placed in the required file.
     The tokens used to expand depend on the file type:

     Read centric files (fastq, (multi-)fast5, protobuf):
      - batch_number:         The batch number of this read, evaluated based on the destination file.
      - read_id:              Unique read id for each read, formatted as a hash.
      - channel_name:         The name of the channel which produced the read.
      - read_start_time:      Read start time formatted in rfc3339 format.
      - basecall_status:      Basecalling output status (derived from WriterDefaults section in analysis config).
      - pore_type:            Type of pore (as specified by #set_pore_type_configuration).

     General attributes:
      - daq_start_time:       Data acquisition start time formatted as YYYYMMDD_hhmm.
      - protocol_start_time:  Time the current protocol was started.
      - run_id:               Acquisition run id formatted as hash.
      - short_run_id:         Shortened version of acquisition run id formatted as hash.
      - protocol_run_id:      Protocol run id formatted as hash.
      - short_protocol_run_id: Shortened protocol run id formatted as hash.
      - asic_id:              Integer id assigned to the asic in the connected flow cell.
      - flow_cell_id:         Flow cell integer as read from eeprom.
      - machine_id:           Name of the machine (hostname or machine identifier depending on the sequencer type).
      - device_id:            Name of the connected sequencing device (eg. MN12345).
      - sample_id:            Sample id entered by the user when starting a protocol.
      - version_string:       Version string of the running MinKNOW instance
      - protocol_group_id:    Protocol group entered by user when starting a protocol.
      - protocol_purpose:     Prupose of protocol (see protocol.set_protocol_purpose())
    """

    read_fast5: "WriterConfigurationReadFast5Configuration" = betterproto.message_field(
        2
    )
    """
    Configuration for the fast5 writer.
    
     If not specified, no multi fast5 outputs are generated.
    """

    read_fastq: "WriterConfigurationReadFastqConfiguration" = betterproto.message_field(
        3
    )
    """
    Configuration for the fastq writer.
    
     If not specified, no fastq outputs are generated.
    """

    read_bam: "WriterConfigurationReadBamConfiguration" = betterproto.message_field(8)
    """
    Configuration for the BAM writer.
    
     If not specified, no BAM outputs are generated.
    """

    read_pod5: "WriterConfigurationReadPod5Configuration" = betterproto.message_field(
        10
    )
    """
    Configuration for the POD5 writer.
    
     If not specified no POD5 outputs are generated.
    """

    sequencing_summary: "WriterConfigurationSequencingSummaryConfiguration" = (
        betterproto.message_field(5)
    )
    """
    Configuration for Sequencing Summary file
    
     If not specified, no summary file is generated.
    """

    bulk: "WriterConfigurationBulkConfiguration" = betterproto.message_field(6)
    """
    Configuration for the bulk writer.
    
     If not specified, a basic bulk output is generated.
    """

    report: "WriterConfigurationReportConfiguration" = betterproto.message_field(7)
    """
    Configuration for the report writer
    
     If acquisition.StartRequest.generate_report is set for the
     acquisition period, and empty paths (or no report config) are supplied
     for reports default paths are used.
    """

    read_filters: "ReadFilters" = betterproto.message_field(9)
    """
    Parameters for filtering reads for writing.  If not present, then
     no filtering will be applied, so no reads will be excluded.
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationChannelConfiguration(betterproto.Message):
    """
    Used to control which channels for a specific
     data type emit data
    """

    all_channels: bool = betterproto.bool_field(1, group="channels")
    specific_channels: "WriterConfigurationChannelConfigurationChannelList" = (
        betterproto.message_field(2, group="channels")
    )
    channel_ranges: "WriterConfigurationChannelConfigurationChannelRanges" = (
        betterproto.message_field(3, group="channels")
    )


@dataclass(eq=False, repr=False)
class WriterConfigurationChannelConfigurationChannelList(betterproto.Message):
    channels: List[int] = betterproto.int32_field(1)
    """
    List of channel names (one based)
     which should be enabled for writing.
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationChannelConfigurationChannelRanges(betterproto.Message):
    ranges: List["WriterConfigurationChannelConfigurationChannelRangesChannelRange"] = (
        betterproto.message_field(1)
    )
    """
    List of start/end paired channel numbers
     which should be enabled for writing.
    
     All channels in inclusive ranges should be enabled.
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationChannelConfigurationChannelRangesChannelRange(
    betterproto.Message
):
    start: int = betterproto.int32_field(1)
    end: int = betterproto.int32_field(2)


@dataclass(eq=False, repr=False)
class WriterConfigurationReadFast5Configuration(betterproto.Message):
    compression_level: int = betterproto.int32_field(1)
    """
    Control the level of compression applied to read data.
    
     0:   No compression will be applied to data.
     1-9: Passed to zlib compression, 1 is the fastest
          compression, 9 is the smallest possible output.
    """

    compression_type: "WriterConfigurationCompressionType" = betterproto.enum_field(14)
    """
    Control the type of compression applied to the read data.
    
     By default the vbz compressor is used (except in the single read case).
    """

    raw: "WriterConfigurationChannelConfiguration" = betterproto.message_field(2)
    """
    Raw data, stored with calibration data, and read attributes.
    
     Stored under /Raw/Reads_*/Signal
    """

    fastq: "WriterConfigurationChannelConfiguration" = betterproto.message_field(3)
    """
    Fastq data, stored as a string.
    
     Stored under /Analyses/Basecall_1D_*/BaseCalled_(template|complement)/Fastq
    """

    trace_table: "WriterConfigurationChannelConfiguration" = betterproto.message_field(
        11
    )
    """
    Trace table received from the basecaller
    
     Stored under /Analyses/Basecall_1D_*/BaseCalled_template/Trace
    """

    move_table: "WriterConfigurationChannelConfiguration" = betterproto.message_field(
        12
    )
    """
    Move table received from the basecaller
    
     Stored under /Analyses/Basecall_1D_*/BaseCalled_template/Move
    """

    modifications_table: "WriterConfigurationChannelConfiguration" = (
        betterproto.message_field(13)
    )
    """
    Base modification probability table
    
     Store under /Analyses/Basecall_1D_*/BaseCalled_template/ModBaseProbs
    """

    disable_writing_passed_reads: bool = betterproto.bool_field(5)
    """
    Prevent reads which have successfully basecalled being written to fast5.
    """

    disable_writing_failed_reads: bool = betterproto.bool_field(6)
    """Prevent reads which have failed basecalling being written to fast5."""

    disable_writing_force_skipped_reads: bool = betterproto.bool_field(7)
    """
    disable writing reads which have been force skipped by the basecaller.
    """

    file_pattern: str = betterproto.string_field(8)
    """
    The pattern used to find a fast5 files name.
    
     default: fast5{basecall_status}/{flow_cell_id}_{run_id}_{batch_number}.fast5
     Where each {xxx} section is replaced with an attribute from the minknow state
     when the file is written.
    
     See file pattern attributes above.
    """

    fastq_header_pattern: str = betterproto.string_field(9)
    """
    The pattern used to find a fastq header.
    
     default: {read_id} runid={run_id} ch={channel_name} start_time={read_start_time}
     Where each {xxx} section is replaced with an attribute from the minknow state
     when the fastq is generated.
    """

    batch_count: int = betterproto.uint32_field(10, group="batch_info")
    """
    How many reads are placed in each batch (after batch_count reads {batch_number}
     is increased in the pattern).
    """

    bases_per_batch: int = betterproto.uint64_field(15, group="batch_info")
    """
    Number of estimated bases within a batch before it rotates to a new batch
    """

    no_output_based_batching: "betterproto_lib_google_protobuf.Empty" = (
        betterproto.message_field(17, group="batch_info")
    )
    """
    Do not perform batching based on output
     (time-based batching is still performed, if specified)
    """

    batch_duration: timedelta = betterproto.message_field(16)
    """
    The batch duration, for time-based batching
    
     If time-based batching is enabled then, in addition to completing batches when the
     `batch_count` or `bases_per_batch` target (above) is reached, batches will also be
     completed when:
     - At least one read has been written to the batch, AND
     - `batch_duration` has elapsed since the last batch was completed (or since the start
       of the acquisition, for the first batch)
    
     If this field is not set, then the default time-based batching configuration will be
     used.  If this field is set to zero or a negative value, then time-based batching will
     be disabled.
    
     Since 5.6
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationReadFastqConfiguration(betterproto.Message):
    enable: "WriterConfigurationChannelConfiguration" = betterproto.message_field(1)
    """Control if a fastq file should be generated per channel."""

    file_pattern: str = betterproto.string_field(2)
    """
    The pattern used to find a fastq files name.
    
     default: fastq{basecall_status}/{flow_cell_id}_{run_id}_{batch_number}.fastq
     Where each {xxx} section is replaced with an attribute from the minknow state when the file is written.
    
     See file pattern attributes above.
    """

    header_pattern: str = betterproto.string_field(3)
    """
    The pattern used to find a fastq header.
    
     default: {read_id} runid={run_id} ch={channel_name} start_time={read_start_time}
     Where each {xxx} section is replaced with an attribute from the minknow state
     when the fastq is generated.
    """

    batch_count: int = betterproto.uint32_field(4, group="batch_info")
    """
    How many reads are placed in each batch (after batch_count reads {batch_number}
     is increased in the pattern).
    """

    bases_per_batch: int = betterproto.uint64_field(6, group="batch_info")
    """
    Number of estimated bases within a batch before it rotates to a new batch
    """

    no_output_based_batching: "betterproto_lib_google_protobuf.Empty" = (
        betterproto.message_field(11, group="batch_info")
    )
    """
    Do not perform batching based on output
     (time-based batching is still performed, if specified)
    """

    compression: bool = betterproto.bool_field(5)
    """
    Compress fastq files with gzip compression.
     default: false
    """

    disable_writing_passed_reads: bool = betterproto.bool_field(7)
    """
    Since 5.8
     Prevent reads which have successfully basecalled being written to fastq.
    """

    disable_writing_failed_reads: bool = betterproto.bool_field(8)
    """Prevent reads which have failed basecalling being written to fastq."""

    disable_writing_force_skipped_reads: bool = betterproto.bool_field(9)
    """
    disable writing reads which have been force skipped by the basecaller.
    """

    batch_duration: timedelta = betterproto.message_field(10)
    """
    The batch duration, for time-based batching
    
     If time-based batching is enabled then, in addition to completing batches when the
     `batch_count` or `bases_per_batch` target (above) is reached, batches will also be
     completed when:
     - At least one read has been written to the batch, AND
     - `batch_duration` has elapsed since the last batch was completed (or since the start
       of the acquisition, for the first batch)
    
     If this field is not set, then the default time-based batching configuration will be
     used.  If this field is set to zero or a negative value, then time-based batching will
     be disabled.
    
     Since 5.6
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationReadBamConfiguration(betterproto.Message):
    enable: "WriterConfigurationChannelConfiguration" = betterproto.message_field(1)
    """Control if a BAM file should be generated per channel."""

    file_pattern: str = betterproto.string_field(2)
    """
    The pattern used to find a BAM files name.
    
     default: bam{basecall_status}/{flow_cell_id}_{run_id}_{batch_number}.bam
     Where each {xxx} section is replaced with an attribute from the minknow state when the file is written.
    
     See file pattern attributes above.
    """

    batch_count: int = betterproto.uint32_field(3, group="batch_info")
    """
    How many reads are placed in each batch (after batch_count reads {batch_number}
     is increased in the pattern).
    """

    bases_per_batch: int = betterproto.uint64_field(5, group="batch_info")
    """
    Number of estimated bases within a batch before it rotates to a new batch
    """

    no_output_based_batching: "betterproto_lib_google_protobuf.Empty" = (
        betterproto.message_field(10, group="batch_info")
    )
    """
    Do not perform batching based on output
     (time-based batching is still performed, if specified)
    """

    disable_writing_multiple_alignments: bool = betterproto.bool_field(4)
    """If true minknow will only write the primary alignment for each read."""

    disable_writing_passed_reads: bool = betterproto.bool_field(6)
    """
    Since 5.8
     Prevent reads which have successfully basecalled being written to bam.
    """

    disable_writing_failed_reads: bool = betterproto.bool_field(7)
    """Prevent reads which have failed basecalling being written to bam."""

    disable_writing_force_skipped_reads: bool = betterproto.bool_field(8)
    """
    disable writing reads which have been force skipped by the basecaller.
    """

    batch_duration: timedelta = betterproto.message_field(9)
    """
    The batch duration, for time-based batching
    
     If time-based batching is enabled then, in addition to completing batches when the
     `batch_count` or `bases_per_batch` target (above) is reached, batches will also be
     completed when:
     - At least one read has been written to the batch, AND
     - `batch_duration` has elapsed since the last batch was completed (or since the start
       of the acquisition, for the first batch)
    
     If this field is not set, then the default time-based batching configuration will be
     used.  If this field is set to zero or a negative value, then time-based batching will
     be disabled.
    
     Since 5.6
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationReadPod5Configuration(betterproto.Message):
    enable: "WriterConfigurationChannelConfiguration" = betterproto.message_field(1)
    """Control if a POD5 file should be generated per channel."""

    file_pattern: str = betterproto.string_field(2)
    """
    The pattern used to find a POD5 files name.
    
     default: pod5{basecall_status}/{flow_cell_id}_{run_id}_{batch_number}.pod5
     Where each {xxx} section is replaced with an attribute from the minknow state when the file is written.
    
     See file pattern attributes above.
    """

    batch_count: int = betterproto.uint32_field(3, group="batch_info")
    """
    How many reads are placed in each batch (after batch_count reads {batch_number}
     is increased in the pattern).
    """

    bases_per_batch: int = betterproto.uint64_field(7, group="batch_info")
    """
    Number of estimated bases within a batch before it rotates to a new batch
    """

    no_output_based_batching: "betterproto_lib_google_protobuf.Empty" = (
        betterproto.message_field(9, group="batch_info")
    )
    """
    Do not perform batching based on output
     (time-based batching is still performed, if specified)
    """

    disable_writing_passed_reads: bool = betterproto.bool_field(4)
    """
    Prevent reads which have successfully basecalled being written to pod5.
    """

    disable_writing_failed_reads: bool = betterproto.bool_field(5)
    """Prevent reads which have failed basecalling being written to pod5."""

    disable_writing_force_skipped_reads: bool = betterproto.bool_field(6)
    """
    disable writing reads which have been force skipped by the basecaller.
    """

    batch_duration: timedelta = betterproto.message_field(8)
    """
    The batch duration, for time-based batching
    
     If time-based batching is enabled then, in addition to completing batches when the
     `batch_count` or `bases_per_batch` target (above) is reached, batches will also be
     completed when:
     - At least one read has been written to the batch, AND
     - `batch_duration` has elapsed since the last batch was completed (or since the start
       of the acquisition, for the first batch)
    
     If this field is not set, then the default time-based batching configuration will be
     used.  If this field is set to zero or a negative value, then time-based batching will
     be disabled.
    
     Since 5.6
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationSequencingSummaryConfiguration(betterproto.Message):
    enable: "WriterConfigurationChannelConfiguration" = betterproto.message_field(1)
    """Should a sequencing summary file be generated"""

    file_pattern: str = betterproto.string_field(2)
    """
    The pattern used to find a summary files name.
    
     default: sequencing_summary_{flow_cell_id}_{short_run_id}.txt
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationBulkConfiguration(betterproto.Message):
    """Control settings for the bulk writer"""

    compression_level: int = betterproto.int32_field(2)
    """
    Control the level of compression applied to read data.
    
     0:   No compression will be applied to data.
     1-9: Passed to zlib compression, 1 is the fastest
          compression, 9 is the smallest possible output.
    """

    compression_type: "WriterConfigurationCompressionType" = betterproto.enum_field(13)
    """
    Control the type of compression applied to the read data.
    
     By default the vbz compressor is used (except in the single read case).
    """

    file_pattern: str = betterproto.string_field(14)
    """
    The pattern used to find a bulk files name. If left empty but output is
     enabled a default pattern is used.
    
     default: {data_set}.fast5
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    raw: "WriterConfigurationChannelConfiguration" = betterproto.message_field(3)
    """
    Raw data, stored with channel calibration data
    
     Stored under /Raw/Channel_*/Signal
    """

    events: "WriterConfigurationChannelConfiguration" = betterproto.message_field(4)
    """
    Minknow event data
    
     Stored under /IntermediateData/Channel_*/Events
    """

    reads: "WriterConfigurationChannelConfiguration" = betterproto.message_field(5)
    """
    Minknow read data
    
     Stored under /IntermediateData/Channel_*/Reads
    """

    multiplex: "WriterConfigurationChannelConfiguration" = betterproto.message_field(6)
    """
    Device multiplex data
    
     Stored under /MultiplexData/Channel_*/Multiplex
    """

    channel_states: "WriterConfigurationChannelConfiguration" = (
        betterproto.message_field(7)
    )
    """
    Channel state data
    
     Stored under /StateData/Channel_*/States
    """

    device_metadata: bool = betterproto.bool_field(11)
    """
    Device metadata (bias and temperature information)
    
     Stored in a per frame sequence in /Device/MetaData
    """

    device_commands: bool = betterproto.bool_field(12)
    """
    Device commands
    
     Stored with the frame commands take effect sequence in /Device/AsicCommands
    """

    dynamic_analysis_config: bool = betterproto.bool_field(15)
    """
    Dynamic analysis configuration
    
     Stored with the frame config took effect in /Meta/User/DynamicAnalysisConfiguration
    """


@dataclass(eq=False, repr=False)
class WriterConfigurationReportConfiguration(betterproto.Message):
    """Control settings for the report writer"""

    pdf_report_file_pattern: str = betterproto.string_field(1)
    """
    DEPRECATED 6.0: As of 5.1 a pdf report is not generated at all. This field will
     be removed in 6.0
    
     The pattern used to find the pdf report filename. If left empty but output is
     enabled a default pattern is used.
    
     default: report_{flow_cell_id}_{daq_start_time}_{short_protocol_run_id}.pdf
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    json_report_file_pattern: str = betterproto.string_field(2)
    """
    The pattern used to find the json report filename. If left empty but output is
     enabled a default pattern is used.
    
     default: report_{flow_cell_id}_{daq_start_time}_{short_protocol_run_id}.json
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    html_report_file_pattern: str = betterproto.string_field(9)
    """
    The pattern used to find the html report filename. If left empty but output is
     enabled a default pattern is used.
    
     default: report_{flow_cell_id}_{daq_start_time}_{short_protocol_run_id}.html
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    markdown_report_file_pattern: str = betterproto.string_field(8)
    """
    The pattern used to find the markdown report filename. If left empty but output is
     enabled a default pattern is used.
    
     default: report_{flow_cell_id}_{daq_start_time}_{short_protocol_run_id}.md
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    duty_time_report_file_pattern: str = betterproto.string_field(3)
    """
    The pattern used to find the duty time csv report. If left empty but output is
     enabled a default pattern is used.
    
     default: duty_time_{flow_cell_id}_{short_run_id}.csv
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    throughput_report_file_pattern: str = betterproto.string_field(4)
    """
    The pattern used to find the throughput csv report. If left empty but output is
     enabled a default pattern is used.
    
     default: throughput_{flow_cell_id}_{short_run_id}.csv
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    final_summary_report_file_pattern: str = betterproto.string_field(5)
    """
    The pattern used to find the final summary report. If left empty but output is
     enabled a default pattern is used.
    
     default: final_summary_{flow_cell_id}_{short_run_id}.txt
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    barcode_alignment_report_file_pattern: str = betterproto.string_field(6)
    """
    The pattern used to name the barcode-alignment report. If left empty but output is
     enabled a default pattern is used.
    
     default: barcode_alignment_{flow_cell_id}_{short_run_id}.tsv
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    sample_sheet_report_file_pattern: str = betterproto.string_field(10)
    """
    The pattern used to name the sample sheet report. If left empty but output is
     enabled a default pattern is used.
    
     default: sample_sheet_{flow_cell_id}_{daq_start_time}_{short_protocol_run_id}.csv
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     See file pattern attributes above.
    """

    custom_report_suffix_pattern: str = betterproto.string_field(7)
    """
    The pattern used to suffix custom reports.
    
     default: "_{flow_cell_id}_{short_run_id}"
     Where each {xxx} section is replaced with an attribute from the minknow
     state when the file is written.
    
     Custom reports use this to build filenames:
       - "custom_report{suffix}.txt"
    
     See file pattern attributes above.
    """


@dataclass(eq=False, repr=False)
class SetWriterConfigurationResponse(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class GetWriterConfigurationRequest(betterproto.Message):
    run_id: str = betterproto.string_field(1)
    """
    The unique identifier assigned to this acquisition run.
    
     Since 6.0
    """


@dataclass(eq=False, repr=False)
class GetReadClassificationsRequest(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class GetReadClassificationsResponse(betterproto.Message):
    read_classifications: Dict[int, str] = betterproto.map_field(
        1, betterproto.TYPE_INT32, betterproto.TYPE_STRING
    )


@dataclass(eq=False, repr=False)
class DynamicAnalysisConfiguration(betterproto.Message):
    read_scale_tracking: "DynamicAnalysisConfigurationReadScaleTracking" = (
        betterproto.message_field(1)
    )
    """Parameters for read scale tracking:"""


@dataclass(eq=False, repr=False)
class DynamicAnalysisConfigurationReadScaleTracking(betterproto.Message):
    conductance_scan_voltage: float = betterproto.float_field(1)
    """Set the voltage the most recent conductance scan occurred at."""

    channel_conductance: List[
        "DynamicAnalysisConfigurationReadScaleTrackingChannelConductance"
    ] = betterproto.message_field(2)
    """Per channel/well conductance values"""


@dataclass(eq=False, repr=False)
class DynamicAnalysisConfigurationReadScaleTrackingChannelConductance(
    betterproto.Message
):
    well_conductance: List[float] = betterproto.float_field(1)
    """Per well conductance values."""


@dataclass(eq=False, repr=False)
class GetDynamicAnalysisConfigurationRequest(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class SetDynamicAnalysisConfigurationResponse(betterproto.Message):
    pass


class AnalysisConfigurationServiceStub(betterproto.ServiceStub):
    async def get_analysis_configuration(
        self,
        get_analysis_configuration_request: "GetAnalysisConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "AnalysisConfiguration":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_analysis_configuration",
            get_analysis_configuration_request,
            AnalysisConfiguration,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def set_analysis_configuration(
        self,
        analysis_configuration: "AnalysisConfiguration",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetAnalysisConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_analysis_configuration",
            analysis_configuration,
            SetAnalysisConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def reset_analysis_configuration(
        self,
        reset_analysis_configuration_request: "ResetAnalysisConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "ResetAnalysisConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/reset_analysis_configuration",
            reset_analysis_configuration_request,
            ResetAnalysisConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def set_analysis_enabled_state(
        self,
        set_analysis_enabled_state_request: "SetAnalysisEnabledStateRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetAnalysisEnabledStateResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_analysis_enabled_state",
            set_analysis_enabled_state_request,
            SetAnalysisEnabledStateResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_channel_states_desc(
        self,
        get_channel_states_desc_request: "GetChannelStatesDescRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "GetChannelStatesDescResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_channel_states_desc",
            get_channel_states_desc_request,
            GetChannelStatesDescResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_summary(
        self,
        get_summary_request: "GetSummaryRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "GetSummaryResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_summary",
            get_summary_request,
            GetSummaryResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def set_basecaller_configuration(
        self,
        set_basecaller_configuration_request: "SetBasecallerConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetBasecallerConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_basecaller_configuration",
            set_basecaller_configuration_request,
            SetBasecallerConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def preload_basecaller_configuration(
        self,
        set_basecaller_configuration_request: "SetBasecallerConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetBasecallerConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/preload_basecaller_configuration",
            set_basecaller_configuration_request,
            SetBasecallerConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_basecaller_configuration(
        self,
        get_basecaller_configuration_request: "GetBasecallerConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "BasecallerConfiguration":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_basecaller_configuration",
            get_basecaller_configuration_request,
            BasecallerConfiguration,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_pore_type_configuration(
        self,
        get_pore_type_configuration_request: "GetPoreTypeConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "PoreTypeConfiguration":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_pore_type_configuration",
            get_pore_type_configuration_request,
            PoreTypeConfiguration,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def set_pore_type_configuration(
        self,
        pore_type_configuration: "PoreTypeConfiguration",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetPoreTypeConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_pore_type_configuration",
            pore_type_configuration,
            SetPoreTypeConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def set_writer_configuration(
        self,
        writer_configuration: "WriterConfiguration",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetWriterConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_writer_configuration",
            writer_configuration,
            SetWriterConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_writer_configuration(
        self,
        get_writer_configuration_request: "GetWriterConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "WriterConfiguration":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_writer_configuration",
            get_writer_configuration_request,
            WriterConfiguration,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_read_classifications(
        self,
        get_read_classifications_request: "GetReadClassificationsRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "GetReadClassificationsResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_read_classifications",
            get_read_classifications_request,
            GetReadClassificationsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_dynamic_analysis_configuration(
        self,
        get_dynamic_analysis_configuration_request: "GetDynamicAnalysisConfigurationRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "DynamicAnalysisConfiguration":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_dynamic_analysis_configuration",
            get_dynamic_analysis_configuration_request,
            DynamicAnalysisConfiguration,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def set_dynamic_analysis_configuration(
        self,
        dynamic_analysis_configuration: "DynamicAnalysisConfiguration",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "SetDynamicAnalysisConfigurationResponse":
        return await self._unary_unary(
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_dynamic_analysis_configuration",
            dynamic_analysis_configuration,
            SetDynamicAnalysisConfigurationResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


class AnalysisConfigurationServiceBase(ServiceBase):

    async def get_analysis_configuration(
        self, get_analysis_configuration_request: "GetAnalysisConfigurationRequest"
    ) -> "AnalysisConfiguration":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def set_analysis_configuration(
        self, analysis_configuration: "AnalysisConfiguration"
    ) -> "SetAnalysisConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def reset_analysis_configuration(
        self, reset_analysis_configuration_request: "ResetAnalysisConfigurationRequest"
    ) -> "ResetAnalysisConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def set_analysis_enabled_state(
        self, set_analysis_enabled_state_request: "SetAnalysisEnabledStateRequest"
    ) -> "SetAnalysisEnabledStateResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_channel_states_desc(
        self, get_channel_states_desc_request: "GetChannelStatesDescRequest"
    ) -> "GetChannelStatesDescResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_summary(
        self, get_summary_request: "GetSummaryRequest"
    ) -> "GetSummaryResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def set_basecaller_configuration(
        self, set_basecaller_configuration_request: "SetBasecallerConfigurationRequest"
    ) -> "SetBasecallerConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def preload_basecaller_configuration(
        self, set_basecaller_configuration_request: "SetBasecallerConfigurationRequest"
    ) -> "SetBasecallerConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_basecaller_configuration(
        self, get_basecaller_configuration_request: "GetBasecallerConfigurationRequest"
    ) -> "BasecallerConfiguration":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_pore_type_configuration(
        self, get_pore_type_configuration_request: "GetPoreTypeConfigurationRequest"
    ) -> "PoreTypeConfiguration":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def set_pore_type_configuration(
        self, pore_type_configuration: "PoreTypeConfiguration"
    ) -> "SetPoreTypeConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def set_writer_configuration(
        self, writer_configuration: "WriterConfiguration"
    ) -> "SetWriterConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_writer_configuration(
        self, get_writer_configuration_request: "GetWriterConfigurationRequest"
    ) -> "WriterConfiguration":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_read_classifications(
        self, get_read_classifications_request: "GetReadClassificationsRequest"
    ) -> "GetReadClassificationsResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_dynamic_analysis_configuration(
        self,
        get_dynamic_analysis_configuration_request: "GetDynamicAnalysisConfigurationRequest",
    ) -> "DynamicAnalysisConfiguration":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def set_dynamic_analysis_configuration(
        self, dynamic_analysis_configuration: "DynamicAnalysisConfiguration"
    ) -> "SetDynamicAnalysisConfigurationResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_get_analysis_configuration(
        self,
        stream: "grpclib.server.Stream[GetAnalysisConfigurationRequest, AnalysisConfiguration]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_analysis_configuration(request)
        await stream.send_message(response)

    async def __rpc_set_analysis_configuration(
        self,
        stream: "grpclib.server.Stream[AnalysisConfiguration, SetAnalysisConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.set_analysis_configuration(request)
        await stream.send_message(response)

    async def __rpc_reset_analysis_configuration(
        self,
        stream: "grpclib.server.Stream[ResetAnalysisConfigurationRequest, ResetAnalysisConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.reset_analysis_configuration(request)
        await stream.send_message(response)

    async def __rpc_set_analysis_enabled_state(
        self,
        stream: "grpclib.server.Stream[SetAnalysisEnabledStateRequest, SetAnalysisEnabledStateResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.set_analysis_enabled_state(request)
        await stream.send_message(response)

    async def __rpc_get_channel_states_desc(
        self,
        stream: "grpclib.server.Stream[GetChannelStatesDescRequest, GetChannelStatesDescResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_channel_states_desc(request)
        await stream.send_message(response)

    async def __rpc_get_summary(
        self, stream: "grpclib.server.Stream[GetSummaryRequest, GetSummaryResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_summary(request)
        await stream.send_message(response)

    async def __rpc_set_basecaller_configuration(
        self,
        stream: "grpclib.server.Stream[SetBasecallerConfigurationRequest, SetBasecallerConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.set_basecaller_configuration(request)
        await stream.send_message(response)

    async def __rpc_preload_basecaller_configuration(
        self,
        stream: "grpclib.server.Stream[SetBasecallerConfigurationRequest, SetBasecallerConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.preload_basecaller_configuration(request)
        await stream.send_message(response)

    async def __rpc_get_basecaller_configuration(
        self,
        stream: "grpclib.server.Stream[GetBasecallerConfigurationRequest, BasecallerConfiguration]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_basecaller_configuration(request)
        await stream.send_message(response)

    async def __rpc_get_pore_type_configuration(
        self,
        stream: "grpclib.server.Stream[GetPoreTypeConfigurationRequest, PoreTypeConfiguration]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_pore_type_configuration(request)
        await stream.send_message(response)

    async def __rpc_set_pore_type_configuration(
        self,
        stream: "grpclib.server.Stream[PoreTypeConfiguration, SetPoreTypeConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.set_pore_type_configuration(request)
        await stream.send_message(response)

    async def __rpc_set_writer_configuration(
        self,
        stream: "grpclib.server.Stream[WriterConfiguration, SetWriterConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.set_writer_configuration(request)
        await stream.send_message(response)

    async def __rpc_get_writer_configuration(
        self,
        stream: "grpclib.server.Stream[GetWriterConfigurationRequest, WriterConfiguration]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_writer_configuration(request)
        await stream.send_message(response)

    async def __rpc_get_read_classifications(
        self,
        stream: "grpclib.server.Stream[GetReadClassificationsRequest, GetReadClassificationsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_read_classifications(request)
        await stream.send_message(response)

    async def __rpc_get_dynamic_analysis_configuration(
        self,
        stream: "grpclib.server.Stream[GetDynamicAnalysisConfigurationRequest, DynamicAnalysisConfiguration]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_dynamic_analysis_configuration(request)
        await stream.send_message(response)

    async def __rpc_set_dynamic_analysis_configuration(
        self,
        stream: "grpclib.server.Stream[DynamicAnalysisConfiguration, SetDynamicAnalysisConfigurationResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.set_dynamic_analysis_configuration(request)
        await stream.send_message(response)

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_analysis_configuration": grpclib.const.Handler(
                self.__rpc_get_analysis_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetAnalysisConfigurationRequest,
                AnalysisConfiguration,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_analysis_configuration": grpclib.const.Handler(
                self.__rpc_set_analysis_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                AnalysisConfiguration,
                SetAnalysisConfigurationResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/reset_analysis_configuration": grpclib.const.Handler(
                self.__rpc_reset_analysis_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                ResetAnalysisConfigurationRequest,
                ResetAnalysisConfigurationResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_analysis_enabled_state": grpclib.const.Handler(
                self.__rpc_set_analysis_enabled_state,
                grpclib.const.Cardinality.UNARY_UNARY,
                SetAnalysisEnabledStateRequest,
                SetAnalysisEnabledStateResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_channel_states_desc": grpclib.const.Handler(
                self.__rpc_get_channel_states_desc,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetChannelStatesDescRequest,
                GetChannelStatesDescResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_summary": grpclib.const.Handler(
                self.__rpc_get_summary,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetSummaryRequest,
                GetSummaryResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_basecaller_configuration": grpclib.const.Handler(
                self.__rpc_set_basecaller_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                SetBasecallerConfigurationRequest,
                SetBasecallerConfigurationResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/preload_basecaller_configuration": grpclib.const.Handler(
                self.__rpc_preload_basecaller_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                SetBasecallerConfigurationRequest,
                SetBasecallerConfigurationResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_basecaller_configuration": grpclib.const.Handler(
                self.__rpc_get_basecaller_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetBasecallerConfigurationRequest,
                BasecallerConfiguration,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_pore_type_configuration": grpclib.const.Handler(
                self.__rpc_get_pore_type_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetPoreTypeConfigurationRequest,
                PoreTypeConfiguration,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_pore_type_configuration": grpclib.const.Handler(
                self.__rpc_set_pore_type_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                PoreTypeConfiguration,
                SetPoreTypeConfigurationResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_writer_configuration": grpclib.const.Handler(
                self.__rpc_set_writer_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                WriterConfiguration,
                SetWriterConfigurationResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_writer_configuration": grpclib.const.Handler(
                self.__rpc_get_writer_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetWriterConfigurationRequest,
                WriterConfiguration,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_read_classifications": grpclib.const.Handler(
                self.__rpc_get_read_classifications,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetReadClassificationsRequest,
                GetReadClassificationsResponse,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/get_dynamic_analysis_configuration": grpclib.const.Handler(
                self.__rpc_get_dynamic_analysis_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDynamicAnalysisConfigurationRequest,
                DynamicAnalysisConfiguration,
            ),
            "/minknow_api.analysis_configuration.AnalysisConfigurationService/set_dynamic_analysis_configuration": grpclib.const.Handler(
                self.__rpc_set_dynamic_analysis_configuration,
                grpclib.const.Cardinality.UNARY_UNARY,
                DynamicAnalysisConfiguration,
                SetDynamicAnalysisConfigurationResponse,
            ),
        }
